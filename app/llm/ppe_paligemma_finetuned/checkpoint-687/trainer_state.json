{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 687,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04371584699453552,
      "grad_norm": 0.5459129214286804,
      "learning_rate": 1.9737991266375546e-05,
      "loss": 1.0252249717712403,
      "step": 10
    },
    {
      "epoch": 0.08743169398907104,
      "grad_norm": 0.4383770525455475,
      "learning_rate": 1.9446870451237266e-05,
      "loss": 1.0185827255249023,
      "step": 20
    },
    {
      "epoch": 0.13114754098360656,
      "grad_norm": 0.2861860692501068,
      "learning_rate": 1.9155749636098983e-05,
      "loss": 0.886384391784668,
      "step": 30
    },
    {
      "epoch": 0.17486338797814208,
      "grad_norm": 0.18940423429012299,
      "learning_rate": 1.88646288209607e-05,
      "loss": 0.7524582386016846,
      "step": 40
    },
    {
      "epoch": 0.2185792349726776,
      "grad_norm": 0.23969769477844238,
      "learning_rate": 1.857350800582242e-05,
      "loss": 0.8068191528320312,
      "step": 50
    },
    {
      "epoch": 0.26229508196721313,
      "grad_norm": 0.18912440538406372,
      "learning_rate": 1.8282387190684136e-05,
      "loss": 0.723362398147583,
      "step": 60
    },
    {
      "epoch": 0.30601092896174864,
      "grad_norm": 0.2667074501514435,
      "learning_rate": 1.7991266375545852e-05,
      "loss": 0.7160014629364013,
      "step": 70
    },
    {
      "epoch": 0.34972677595628415,
      "grad_norm": 0.18361163139343262,
      "learning_rate": 1.7700145560407572e-05,
      "loss": 0.7198263168334961,
      "step": 80
    },
    {
      "epoch": 0.39344262295081966,
      "grad_norm": 0.2683200240135193,
      "learning_rate": 1.740902474526929e-05,
      "loss": 0.6875846862792969,
      "step": 90
    },
    {
      "epoch": 0.4371584699453552,
      "grad_norm": 0.29943418502807617,
      "learning_rate": 1.7117903930131005e-05,
      "loss": 0.8568636894226074,
      "step": 100
    },
    {
      "epoch": 0.4808743169398907,
      "grad_norm": 0.1978500634431839,
      "learning_rate": 1.6826783114992725e-05,
      "loss": 0.6415920734405518,
      "step": 110
    },
    {
      "epoch": 0.5245901639344263,
      "grad_norm": 0.2701972424983978,
      "learning_rate": 1.653566229985444e-05,
      "loss": 0.7471744060516358,
      "step": 120
    },
    {
      "epoch": 0.5683060109289617,
      "grad_norm": 0.19669389724731445,
      "learning_rate": 1.6244541484716158e-05,
      "loss": 0.7889661312103271,
      "step": 130
    },
    {
      "epoch": 0.6120218579234973,
      "grad_norm": 0.48678019642829895,
      "learning_rate": 1.5953420669577878e-05,
      "loss": 0.7127766609191895,
      "step": 140
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.3590810298919678,
      "learning_rate": 1.5662299854439594e-05,
      "loss": 0.6688150405883789,
      "step": 150
    },
    {
      "epoch": 0.6994535519125683,
      "grad_norm": 0.22001959383487701,
      "learning_rate": 1.537117903930131e-05,
      "loss": 0.6737051963806152,
      "step": 160
    },
    {
      "epoch": 0.7431693989071039,
      "grad_norm": 0.2839970588684082,
      "learning_rate": 1.5080058224163027e-05,
      "loss": 0.6433231830596924,
      "step": 170
    },
    {
      "epoch": 0.7868852459016393,
      "grad_norm": 0.24332158267498016,
      "learning_rate": 1.4788937409024746e-05,
      "loss": 0.6458055019378662,
      "step": 180
    },
    {
      "epoch": 0.8306010928961749,
      "grad_norm": 0.3189407289028168,
      "learning_rate": 1.4497816593886464e-05,
      "loss": 0.696226167678833,
      "step": 190
    },
    {
      "epoch": 0.8743169398907104,
      "grad_norm": 0.2920302450656891,
      "learning_rate": 1.420669577874818e-05,
      "loss": 0.6351341724395752,
      "step": 200
    },
    {
      "epoch": 0.9180327868852459,
      "grad_norm": 0.33561140298843384,
      "learning_rate": 1.3915574963609899e-05,
      "loss": 0.7121552944183349,
      "step": 210
    },
    {
      "epoch": 0.9617486338797814,
      "grad_norm": 0.21140091121196747,
      "learning_rate": 1.3624454148471617e-05,
      "loss": 0.6821213245391846,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6568695902824402,
      "eval_runtime": 15.0235,
      "eval_samples_per_second": 30.419,
      "eval_steps_per_second": 3.861,
      "step": 229
    },
    {
      "epoch": 1.0043715846994536,
      "grad_norm": 0.28994545340538025,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.6359604358673095,
      "step": 230
    },
    {
      "epoch": 1.048087431693989,
      "grad_norm": 0.32067567110061646,
      "learning_rate": 1.3042212518195051e-05,
      "loss": 0.6159309387207031,
      "step": 240
    },
    {
      "epoch": 1.0918032786885246,
      "grad_norm": 0.27907389402389526,
      "learning_rate": 1.275109170305677e-05,
      "loss": 0.6252296447753907,
      "step": 250
    },
    {
      "epoch": 1.1355191256830601,
      "grad_norm": 0.21437954902648926,
      "learning_rate": 1.2459970887918486e-05,
      "loss": 0.6251477718353271,
      "step": 260
    },
    {
      "epoch": 1.1792349726775957,
      "grad_norm": 0.39796537160873413,
      "learning_rate": 1.2168850072780204e-05,
      "loss": 0.6548422813415528,
      "step": 270
    },
    {
      "epoch": 1.222950819672131,
      "grad_norm": 0.2622304856777191,
      "learning_rate": 1.1877729257641923e-05,
      "loss": 0.6327871322631836,
      "step": 280
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.22708210349082947,
      "learning_rate": 1.1586608442503639e-05,
      "loss": 0.6537880897521973,
      "step": 290
    },
    {
      "epoch": 1.3103825136612022,
      "grad_norm": 0.30450379848480225,
      "learning_rate": 1.1295487627365357e-05,
      "loss": 0.6482481002807617,
      "step": 300
    },
    {
      "epoch": 1.3540983606557377,
      "grad_norm": 0.3403383195400238,
      "learning_rate": 1.1004366812227074e-05,
      "loss": 0.6659204959869385,
      "step": 310
    },
    {
      "epoch": 1.3978142076502733,
      "grad_norm": 0.20732207596302032,
      "learning_rate": 1.0713245997088792e-05,
      "loss": 0.6688097953796387,
      "step": 320
    },
    {
      "epoch": 1.4415300546448089,
      "grad_norm": 0.3693019449710846,
      "learning_rate": 1.042212518195051e-05,
      "loss": 0.6353093147277832,
      "step": 330
    },
    {
      "epoch": 1.4852459016393442,
      "grad_norm": 0.4328390955924988,
      "learning_rate": 1.0160116448326057e-05,
      "loss": 0.6648347854614258,
      "step": 340
    },
    {
      "epoch": 1.5289617486338798,
      "grad_norm": 0.34596893191337585,
      "learning_rate": 9.868995633187773e-06,
      "loss": 0.7990904808044433,
      "step": 350
    },
    {
      "epoch": 1.5726775956284151,
      "grad_norm": 0.30099835991859436,
      "learning_rate": 9.577874818049491e-06,
      "loss": 0.5898797512054443,
      "step": 360
    },
    {
      "epoch": 1.6163934426229507,
      "grad_norm": 0.29321977496147156,
      "learning_rate": 9.28675400291121e-06,
      "loss": 0.6668848514556884,
      "step": 370
    },
    {
      "epoch": 1.6601092896174863,
      "grad_norm": 0.4039832353591919,
      "learning_rate": 8.995633187772926e-06,
      "loss": 0.6448951244354248,
      "step": 380
    },
    {
      "epoch": 1.7038251366120218,
      "grad_norm": 0.3240620791912079,
      "learning_rate": 8.704512372634644e-06,
      "loss": 0.6214056491851807,
      "step": 390
    },
    {
      "epoch": 1.7475409836065574,
      "grad_norm": 0.5763649344444275,
      "learning_rate": 8.413391557496363e-06,
      "loss": 0.6561781883239746,
      "step": 400
    },
    {
      "epoch": 1.791256830601093,
      "grad_norm": 0.4285973906517029,
      "learning_rate": 8.122270742358079e-06,
      "loss": 0.6644432067871093,
      "step": 410
    },
    {
      "epoch": 1.8349726775956285,
      "grad_norm": 0.4139315187931061,
      "learning_rate": 7.831149927219797e-06,
      "loss": 0.5747190952301026,
      "step": 420
    },
    {
      "epoch": 1.8786885245901639,
      "grad_norm": 0.5220317840576172,
      "learning_rate": 7.540029112081514e-06,
      "loss": 0.6197879314422607,
      "step": 430
    },
    {
      "epoch": 1.9224043715846995,
      "grad_norm": 0.30831125378608704,
      "learning_rate": 7.248908296943232e-06,
      "loss": 0.5804455280303955,
      "step": 440
    },
    {
      "epoch": 1.966120218579235,
      "grad_norm": 0.27357521653175354,
      "learning_rate": 6.957787481804949e-06,
      "loss": 0.599368953704834,
      "step": 450
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6344776153564453,
      "eval_runtime": 15.2285,
      "eval_samples_per_second": 30.01,
      "eval_steps_per_second": 3.809,
      "step": 458
    },
    {
      "epoch": 2.0087431693989073,
      "grad_norm": 0.42158326506614685,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.5887342929840088,
      "step": 460
    },
    {
      "epoch": 2.0524590163934424,
      "grad_norm": 0.25959113240242004,
      "learning_rate": 6.375545851528385e-06,
      "loss": 0.6590648174285889,
      "step": 470
    },
    {
      "epoch": 2.096174863387978,
      "grad_norm": 0.30674582719802856,
      "learning_rate": 6.084425036390102e-06,
      "loss": 0.7171213626861572,
      "step": 480
    },
    {
      "epoch": 2.1398907103825136,
      "grad_norm": 0.2995023727416992,
      "learning_rate": 5.7933042212518195e-06,
      "loss": 0.6044068813323975,
      "step": 490
    },
    {
      "epoch": 2.183606557377049,
      "grad_norm": 0.30919283628463745,
      "learning_rate": 5.502183406113537e-06,
      "loss": 0.5501353740692139,
      "step": 500
    },
    {
      "epoch": 2.2273224043715847,
      "grad_norm": 0.311040461063385,
      "learning_rate": 5.211062590975255e-06,
      "loss": 0.6360220432281494,
      "step": 510
    },
    {
      "epoch": 2.2710382513661203,
      "grad_norm": 0.3067510724067688,
      "learning_rate": 4.9199417758369724e-06,
      "loss": 0.6853717803955078,
      "step": 520
    },
    {
      "epoch": 2.314754098360656,
      "grad_norm": 0.4313686192035675,
      "learning_rate": 4.628820960698691e-06,
      "loss": 0.6142423629760743,
      "step": 530
    },
    {
      "epoch": 2.3584699453551914,
      "grad_norm": 0.2993878722190857,
      "learning_rate": 4.337700145560408e-06,
      "loss": 0.6194622039794921,
      "step": 540
    },
    {
      "epoch": 2.402185792349727,
      "grad_norm": 0.5762327313423157,
      "learning_rate": 4.046579330422125e-06,
      "loss": 0.6498357772827148,
      "step": 550
    },
    {
      "epoch": 2.445901639344262,
      "grad_norm": 0.39922383427619934,
      "learning_rate": 3.755458515283843e-06,
      "loss": 0.6152719497680664,
      "step": 560
    },
    {
      "epoch": 2.4896174863387976,
      "grad_norm": 0.5955914855003357,
      "learning_rate": 3.464337700145561e-06,
      "loss": 0.6392261505126953,
      "step": 570
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.39133578538894653,
      "learning_rate": 3.1732168850072782e-06,
      "loss": 0.6124844551086426,
      "step": 580
    },
    {
      "epoch": 2.577049180327869,
      "grad_norm": 0.350627601146698,
      "learning_rate": 2.882096069868996e-06,
      "loss": 0.6439587116241455,
      "step": 590
    },
    {
      "epoch": 2.6207650273224044,
      "grad_norm": 0.6234355568885803,
      "learning_rate": 2.5909752547307134e-06,
      "loss": 0.7079519748687744,
      "step": 600
    },
    {
      "epoch": 2.66448087431694,
      "grad_norm": 0.34283602237701416,
      "learning_rate": 2.299854439592431e-06,
      "loss": 0.5692308425903321,
      "step": 610
    },
    {
      "epoch": 2.7081967213114755,
      "grad_norm": 0.40818914771080017,
      "learning_rate": 2.0087336244541485e-06,
      "loss": 0.6511606693267822,
      "step": 620
    },
    {
      "epoch": 2.751912568306011,
      "grad_norm": 0.3704621195793152,
      "learning_rate": 1.717612809315866e-06,
      "loss": 0.5797977447509766,
      "step": 630
    },
    {
      "epoch": 2.7956284153005466,
      "grad_norm": 0.3376150131225586,
      "learning_rate": 1.4264919941775836e-06,
      "loss": 0.5469189167022706,
      "step": 640
    },
    {
      "epoch": 2.839344262295082,
      "grad_norm": 0.3323666751384735,
      "learning_rate": 1.1353711790393014e-06,
      "loss": 0.5153737545013428,
      "step": 650
    },
    {
      "epoch": 2.8830601092896178,
      "grad_norm": 0.47236505150794983,
      "learning_rate": 8.44250363901019e-07,
      "loss": 0.6446466445922852,
      "step": 660
    },
    {
      "epoch": 2.926775956284153,
      "grad_norm": 0.3587195873260498,
      "learning_rate": 5.531295487627366e-07,
      "loss": 0.6226712703704834,
      "step": 670
    },
    {
      "epoch": 2.9704918032786884,
      "grad_norm": 0.43299558758735657,
      "learning_rate": 2.6200873362445414e-07,
      "loss": 0.6055779933929444,
      "step": 680
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6298496723175049,
      "eval_runtime": 15.0442,
      "eval_samples_per_second": 30.377,
      "eval_steps_per_second": 3.855,
      "step": 687
    }
  ],
  "logging_steps": 10,
  "max_steps": 687,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.067498832134963e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
