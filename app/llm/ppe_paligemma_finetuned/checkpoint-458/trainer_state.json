{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 458,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04371584699453552,
      "grad_norm": 0.5459129214286804,
      "learning_rate": 1.9737991266375546e-05,
      "loss": 1.0252249717712403,
      "step": 10
    },
    {
      "epoch": 0.08743169398907104,
      "grad_norm": 0.4383770525455475,
      "learning_rate": 1.9446870451237266e-05,
      "loss": 1.0185827255249023,
      "step": 20
    },
    {
      "epoch": 0.13114754098360656,
      "grad_norm": 0.2861860692501068,
      "learning_rate": 1.9155749636098983e-05,
      "loss": 0.886384391784668,
      "step": 30
    },
    {
      "epoch": 0.17486338797814208,
      "grad_norm": 0.18940423429012299,
      "learning_rate": 1.88646288209607e-05,
      "loss": 0.7524582386016846,
      "step": 40
    },
    {
      "epoch": 0.2185792349726776,
      "grad_norm": 0.23969769477844238,
      "learning_rate": 1.857350800582242e-05,
      "loss": 0.8068191528320312,
      "step": 50
    },
    {
      "epoch": 0.26229508196721313,
      "grad_norm": 0.18912440538406372,
      "learning_rate": 1.8282387190684136e-05,
      "loss": 0.723362398147583,
      "step": 60
    },
    {
      "epoch": 0.30601092896174864,
      "grad_norm": 0.2667074501514435,
      "learning_rate": 1.7991266375545852e-05,
      "loss": 0.7160014629364013,
      "step": 70
    },
    {
      "epoch": 0.34972677595628415,
      "grad_norm": 0.18361163139343262,
      "learning_rate": 1.7700145560407572e-05,
      "loss": 0.7198263168334961,
      "step": 80
    },
    {
      "epoch": 0.39344262295081966,
      "grad_norm": 0.2683200240135193,
      "learning_rate": 1.740902474526929e-05,
      "loss": 0.6875846862792969,
      "step": 90
    },
    {
      "epoch": 0.4371584699453552,
      "grad_norm": 0.29943418502807617,
      "learning_rate": 1.7117903930131005e-05,
      "loss": 0.8568636894226074,
      "step": 100
    },
    {
      "epoch": 0.4808743169398907,
      "grad_norm": 0.1978500634431839,
      "learning_rate": 1.6826783114992725e-05,
      "loss": 0.6415920734405518,
      "step": 110
    },
    {
      "epoch": 0.5245901639344263,
      "grad_norm": 0.2701972424983978,
      "learning_rate": 1.653566229985444e-05,
      "loss": 0.7471744060516358,
      "step": 120
    },
    {
      "epoch": 0.5683060109289617,
      "grad_norm": 0.19669389724731445,
      "learning_rate": 1.6244541484716158e-05,
      "loss": 0.7889661312103271,
      "step": 130
    },
    {
      "epoch": 0.6120218579234973,
      "grad_norm": 0.48678019642829895,
      "learning_rate": 1.5953420669577878e-05,
      "loss": 0.7127766609191895,
      "step": 140
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.3590810298919678,
      "learning_rate": 1.5662299854439594e-05,
      "loss": 0.6688150405883789,
      "step": 150
    },
    {
      "epoch": 0.6994535519125683,
      "grad_norm": 0.22001959383487701,
      "learning_rate": 1.537117903930131e-05,
      "loss": 0.6737051963806152,
      "step": 160
    },
    {
      "epoch": 0.7431693989071039,
      "grad_norm": 0.2839970588684082,
      "learning_rate": 1.5080058224163027e-05,
      "loss": 0.6433231830596924,
      "step": 170
    },
    {
      "epoch": 0.7868852459016393,
      "grad_norm": 0.24332158267498016,
      "learning_rate": 1.4788937409024746e-05,
      "loss": 0.6458055019378662,
      "step": 180
    },
    {
      "epoch": 0.8306010928961749,
      "grad_norm": 0.3189407289028168,
      "learning_rate": 1.4497816593886464e-05,
      "loss": 0.696226167678833,
      "step": 190
    },
    {
      "epoch": 0.8743169398907104,
      "grad_norm": 0.2920302450656891,
      "learning_rate": 1.420669577874818e-05,
      "loss": 0.6351341724395752,
      "step": 200
    },
    {
      "epoch": 0.9180327868852459,
      "grad_norm": 0.33561140298843384,
      "learning_rate": 1.3915574963609899e-05,
      "loss": 0.7121552944183349,
      "step": 210
    },
    {
      "epoch": 0.9617486338797814,
      "grad_norm": 0.21140091121196747,
      "learning_rate": 1.3624454148471617e-05,
      "loss": 0.6821213245391846,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6568695902824402,
      "eval_runtime": 15.0235,
      "eval_samples_per_second": 30.419,
      "eval_steps_per_second": 3.861,
      "step": 229
    },
    {
      "epoch": 1.0043715846994536,
      "grad_norm": 0.28994545340538025,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.6359604358673095,
      "step": 230
    },
    {
      "epoch": 1.048087431693989,
      "grad_norm": 0.32067567110061646,
      "learning_rate": 1.3042212518195051e-05,
      "loss": 0.6159309387207031,
      "step": 240
    },
    {
      "epoch": 1.0918032786885246,
      "grad_norm": 0.27907389402389526,
      "learning_rate": 1.275109170305677e-05,
      "loss": 0.6252296447753907,
      "step": 250
    },
    {
      "epoch": 1.1355191256830601,
      "grad_norm": 0.21437954902648926,
      "learning_rate": 1.2459970887918486e-05,
      "loss": 0.6251477718353271,
      "step": 260
    },
    {
      "epoch": 1.1792349726775957,
      "grad_norm": 0.39796537160873413,
      "learning_rate": 1.2168850072780204e-05,
      "loss": 0.6548422813415528,
      "step": 270
    },
    {
      "epoch": 1.222950819672131,
      "grad_norm": 0.2622304856777191,
      "learning_rate": 1.1877729257641923e-05,
      "loss": 0.6327871322631836,
      "step": 280
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.22708210349082947,
      "learning_rate": 1.1586608442503639e-05,
      "loss": 0.6537880897521973,
      "step": 290
    },
    {
      "epoch": 1.3103825136612022,
      "grad_norm": 0.30450379848480225,
      "learning_rate": 1.1295487627365357e-05,
      "loss": 0.6482481002807617,
      "step": 300
    },
    {
      "epoch": 1.3540983606557377,
      "grad_norm": 0.3403383195400238,
      "learning_rate": 1.1004366812227074e-05,
      "loss": 0.6659204959869385,
      "step": 310
    },
    {
      "epoch": 1.3978142076502733,
      "grad_norm": 0.20732207596302032,
      "learning_rate": 1.0713245997088792e-05,
      "loss": 0.6688097953796387,
      "step": 320
    },
    {
      "epoch": 1.4415300546448089,
      "grad_norm": 0.3693019449710846,
      "learning_rate": 1.042212518195051e-05,
      "loss": 0.6353093147277832,
      "step": 330
    },
    {
      "epoch": 1.4852459016393442,
      "grad_norm": 0.4328390955924988,
      "learning_rate": 1.0160116448326057e-05,
      "loss": 0.6648347854614258,
      "step": 340
    },
    {
      "epoch": 1.5289617486338798,
      "grad_norm": 0.34596893191337585,
      "learning_rate": 9.868995633187773e-06,
      "loss": 0.7990904808044433,
      "step": 350
    },
    {
      "epoch": 1.5726775956284151,
      "grad_norm": 0.30099835991859436,
      "learning_rate": 9.577874818049491e-06,
      "loss": 0.5898797512054443,
      "step": 360
    },
    {
      "epoch": 1.6163934426229507,
      "grad_norm": 0.29321977496147156,
      "learning_rate": 9.28675400291121e-06,
      "loss": 0.6668848514556884,
      "step": 370
    },
    {
      "epoch": 1.6601092896174863,
      "grad_norm": 0.4039832353591919,
      "learning_rate": 8.995633187772926e-06,
      "loss": 0.6448951244354248,
      "step": 380
    },
    {
      "epoch": 1.7038251366120218,
      "grad_norm": 0.3240620791912079,
      "learning_rate": 8.704512372634644e-06,
      "loss": 0.6214056491851807,
      "step": 390
    },
    {
      "epoch": 1.7475409836065574,
      "grad_norm": 0.5763649344444275,
      "learning_rate": 8.413391557496363e-06,
      "loss": 0.6561781883239746,
      "step": 400
    },
    {
      "epoch": 1.791256830601093,
      "grad_norm": 0.4285973906517029,
      "learning_rate": 8.122270742358079e-06,
      "loss": 0.6644432067871093,
      "step": 410
    },
    {
      "epoch": 1.8349726775956285,
      "grad_norm": 0.4139315187931061,
      "learning_rate": 7.831149927219797e-06,
      "loss": 0.5747190952301026,
      "step": 420
    },
    {
      "epoch": 1.8786885245901639,
      "grad_norm": 0.5220317840576172,
      "learning_rate": 7.540029112081514e-06,
      "loss": 0.6197879314422607,
      "step": 430
    },
    {
      "epoch": 1.9224043715846995,
      "grad_norm": 0.30831125378608704,
      "learning_rate": 7.248908296943232e-06,
      "loss": 0.5804455280303955,
      "step": 440
    },
    {
      "epoch": 1.966120218579235,
      "grad_norm": 0.27357521653175354,
      "learning_rate": 6.957787481804949e-06,
      "loss": 0.599368953704834,
      "step": 450
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6344776153564453,
      "eval_runtime": 15.2285,
      "eval_samples_per_second": 30.01,
      "eval_steps_per_second": 3.809,
      "step": 458
    }
  ],
  "logging_steps": 10,
  "max_steps": 687,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.044999221423309e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
